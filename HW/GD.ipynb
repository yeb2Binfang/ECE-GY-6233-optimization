{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "GD.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUsKMIP_cszi"
      },
      "source": [
        "## Coding Problem\n",
        "<br>\n",
        "Consider the following unconstrained minimization problem\n",
        "$$\n",
        "\\min_{x\\in R^3} f(x) = \\frac{1}{2}x^T Ax + x^T b\n",
        "$$\n",
        "where $A$ and $b$ are defined as\n",
        "$$\n",
        "A = \\begin{bmatrix}\n",
        "2 & -1 & 0\\\\\n",
        "-1 & 2 & -1\\\\\n",
        "0 & -1 & 2\n",
        "\\end{bmatrix}\n",
        "\\qquad \n",
        "b = \\begin{bmatrix}\n",
        "1\\\\ 1\\\\ 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HitT6H4Kc1J-"
      },
      "source": [
        "1. Determine whether the matrix $A$ is positive definite and find the minimum of $f$​​ if exists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roxe3hIcc7zE",
        "outputId": "06416f98-4a23-444a-9767-12721cb07316",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "A_1 = 2\n",
        "A_2 = np.array([[2,-1],[-1,2]])\n",
        "A_3 = np.array([[2,-1,0],[-1,2,-1],[0,-1,2]])\n",
        "\n",
        "det_2 = np.linalg.det(A_2)\n",
        "det_3 = np.linalg.det(A_3)\n",
        "print(det_2)\n",
        "print(det_3)\n",
        "A=np.linalg.inv(A_3)\n",
        "b=np.ones(3)\n",
        "x = -A.dot(b)\n",
        "print(np.transpose(x).dot(A).dot(x)+np.transpose(x).dot(b))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9999999999999996\n",
            "4.0\n",
            "9.499999999999998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOcVrH0fcszl"
      },
      "source": [
        "2. Implement the gradient descent method with backtracking line search starting with $x_0=[1,1,1]^T$. Let the maximum iteration number be $50$, $\\alpha=0.25$ and $\\beta=0.1$. Record the function value of each iteration and plot it (x-axis: number of iterations / y-axis: function value of that iteration). </br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZeitxqSOLzr",
        "outputId": "23bcdb5f-0384-45e1-cb32-2d07cc90230a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "A = np.array([[2,-1,0],[-1,2,-1],[0,-1,2]])\n",
        "b=np.ones(3)\n",
        "x = np.ones(3)\n",
        "print(obj_grad(x,A))\n",
        "print(b)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 1. 2.]\n",
            "[1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3a5JatKFcsn"
      },
      "source": [
        "def obj(x,A):\n",
        "  f = 0.5 * x.T.dot(A).dot(x)+b.T.dot(x)\n",
        "  return f\n",
        "\n",
        "def obj_grad(x,A):\n",
        "  f_grad = A.dot(x) + b\n",
        "  return f_grad"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLJpDGd4WdOK",
        "outputId": "b307bbee-460a-4ef3-9f2e-4805c4345644",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(obj_grad(x,A).T.dot(obj_grad(x,A)))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNSIUSWPcszo"
      },
      "source": [
        "# Code goes here\n",
        "\n",
        "def backtracking(x, A, alpha, beta, t, maxIter):\n",
        "  val = []\n",
        "  it = 1\n",
        "  while it<=maxIter:\n",
        "    it+=1\n",
        "    grad = -obj_grad(x, A)\n",
        "    \n",
        "    left = obj(x + t * grad, A)\n",
        "    right = obj(x, A) + alpha * t * grad.T.dot(grad)\n",
        "    #print(grad.T.dot(grad))\n",
        "    while left > right:\n",
        "      t = beta * t  \n",
        "      print(t)  \n",
        "      left = obj(x + t*grad, A)\n",
        "      right = obj(x, A) + alpha * t * grad.T.dot(grad)\n",
        "    x = x + t*grad\n",
        "    val.append(obj(x,A))\n",
        "  return val\n"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1BQUi_4W2Z7",
        "outputId": "a3cbd58a-266c-4934-c3c5-7f5cb18ad3e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "A = np.array([[2,-1,0],[-1,2,-1],[0,-1,2]])\n",
        "alpha = 0.25\n",
        "beta = 0.1\n",
        "t=1\n",
        "x=np.ones(3)\n",
        "maxIter = 50\n",
        "val = backtracking(x, A, alpha, beta, t, maxIter)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT3uqIs0Qilw",
        "outputId": "8d851a17-42bf-4aa7-9593-fac43ae8f9e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(val)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, -0.9299999999999999, -1.3886000000000003, -1.6364600000000002, -1.78734936, -1.8912459311999998, -1.9703875352000004, -2.03491661051072, -2.08967295734327, -2.1371463586127963, -2.1787629085661377, -2.215447979056543, -2.2478748703018137, -2.276576625649059, -2.30199804571274, -2.324521365441319, -2.3444801536105637, -2.362167789890301, -2.377843311607297, -2.3917358728878004, -2.4040483832300508, -2.4149605963255967, -2.424631788636156, -2.433203107772167, -2.440799642707522, -2.4475322537463087, -2.453499192288356, -2.458787535480547, -2.4634744573186795, -2.4676283550219344, -2.471309847235652, -2.47457265868063, -2.4774644041810467, -2.4800272835221486, -2.48229869728204, -2.4843117926263805, -2.4860959470316057, -2.4876771969961387, -2.4890786179959536, -2.490320661229344, -2.4914214520650884, -2.492397054549357, -2.4932617058313316, -2.494028023928585, -2.494707191864168, -2.495309120862553, -2.4958425949859846, -2.4963153993219342, -2.496734433592341, -2.497105812842538]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWU_p8JRcszr"
      },
      "source": [
        "# Plot the function value each iteration\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7KeH6IUcszs"
      },
      "source": [
        "3. Change the learning rate to $\\beta=0.3$ and $\\beta=0.8$, repeate the process in (2) and plot the function values. Comment on how the learning rate will affect the gradient descent method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufrmo1HKcszt"
      },
      "source": [
        "# Code goes here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPnS-Jztcszu"
      },
      "source": [
        "# Plot the function value each iteration (for different beta)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}